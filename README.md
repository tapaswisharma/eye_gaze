# eye_gaze


This study developed an eye-controlled virtual keyboard for differently-abled individuals, enabling text-based interactions through eye movements and blinks. Using TensorFlow and neural networks, the system accurately predicts eye states to operate the keyboard. The study successfully created an efficient solution for the target audience, highlighting the importance of accessible digital technologies and paving the way for future advancements



## REQUIREMENTS:

1.OpenCV (cv2).
2.math (hypot).
3.NumPy (numpy).
4.Dlib (dlib).
5.Pyglet (pyglet).

## flowchart:
![flow chart ](https://github.com/user-attachments/assets/b6b0a50c-ce12-47ad-99cc-eb5c2642d82e)

## EYE POINTS:

Left eye points: (36, 37, 38, 39, 40, 41)
Right eye points: (42, 43, 44, 45, 46, 47)


## DATA SETS: 


Kaggle eyeblink dataset: https://www.kaggle.com/datasets/nikospetrellis/nitymed.
Eyeblink using CNN: https://github.com/kairess/eye_blink_detector.
Eye gaze data set kaggle: https://www.kaggle.com/datasets/4quant/eye-gaze. 
Gaze tracking library: https://github.com/antoinelame/GazeTracking.

